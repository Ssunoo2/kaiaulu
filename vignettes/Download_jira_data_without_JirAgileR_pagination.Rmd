---
title: "Download JIRA Issues and Comments"
output: 
  html_document:
    toc: true
    number_sections: true
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Download JIRA Issues and Commentss}
  %\VignetteEncoding{UTF-8}
---


```{r}
rm(list = ls())
seed <- 1
set.seed(seed)
```

```{r warning=FALSE,message=FALSE}
require(kaiaulu)
require(data.table)
#require(JirAgileR)
require(knitr, quietly = T)
require(dplyr, quietly = T)
require(jsonlite)
```

# Introduction

This example is adapted from the JirAgileR package [README.md](https://github.com/matbmeijer/JirAgileR). 

As usual, the first step is to load the project configuration file. 

# Project Configuration File

In this notebook, we will obtain data from the issue tracker JIRA. We will use [Apache's Geronimo open source project](https://geronimo.apache.org). Refer to the `conf/` folder on Kaiaulu's git repository for Geronimo and other project configuration files. It is in this project configuration file we specify where Kaiaulu can find the jira sources from Geronimo. We will use the issue_tracker -> jira fields only. In regards to the "issues" and "issue_comments" fields, these should be set to paths where you want to store the jira data. Then, you can access this jira data later using these same paths.

# your_api_token is your atlassian token that is used as your password. Your username is your atlassian username (usually your email). These can be created by navigating to the indicated directories and creating a plain text file (vim atlassian_username) and typing in your username. Details on how to obtain an atlassian token can be found here: https://support.atlassian.com/atlassian-account/docs/manage-api-tokens-for-your-atlassian-account/

```{r}
conf <- yaml::read_yaml("../conf/geronimo.yml")
issue_tracker_domain <- conf[["issue_tracker"]][["jira"]][["domain"]]
issue_tracker_project_key <- conf[["issue_tracker"]][["jira"]][["project_key"]]
save_path_issue_tracker_issues <- conf[["issue_tracker"]][["jira"]][["issues"]]
save_path_issue_tracker_issue_comments <- conf[["issue_tracker"]][["jira"]][["issue_comments"]]
your_api_token <- scan("~/.ssh/atlassian_token",what="character",quiet=TRUE)
username <- scan("~/atlassian_username",what="character",quiet=TRUE)

```


# Define a function for pulling issue data (without comments) from JIRA API. Note that you must create an Atlassian token and use it for your password. Info on how to make a token can be found here: https://support.atlassian.com/atlassian-account/docs/manage-api-tokens-for-your-atlassian-account/

```{r eval=FALSE}
#' @title Define function to fetch issues from JIRA REST API and save as JSON
#' @description Makes a request to JIRA's latest REST API to retrieve all
#' the necessary information regarding the JIRA issues and downloand
#' them to path designated save_path_issue_tracker_issues
#' @param username
#' @param password this is your password
#' @param domain Custom JIRA domain URL 
#' @param jql_query the specific query string to specify criteria for fetching
#' @param fields the list of fields that are downloaded in each issue
#' @param maxResults (optional) the maximum number of results to download
#' defaul is 50
#' @param verbose boolean flag to specify printing operational 
#' messages or not
fetch_and_save_jira_issues <- function(domain, 
                                       username = NULL,
                                       password = NULL,
                                       jql_query, 
                                       fields, 
                                       save_path_issue_tracker_issues,  
                                       maxResults = 50, 
                                       verbose = FALSE) {
  
  # Check if domain starts with https:// and if not, prepends it to ensure
  # secure protocol
  if (!grepl("^https?://", domain)) {
    domain <- paste0("https://", domain)
  }
  
  # If username and password is present, then authenticate
  if(!is.null(username)&&!is.null(password)){
    auth <- httr::authenticate(as.character(username), as.character(password), "basic")
  } else {
    auth <- NULL
  }
  
  # Construct the API endpoint URL. appends /rest/api/latest/search to domain
  url <- paste0(domain, "/rest/api/latest/search")
  
  #initialize empty list to store fetched issues
  all_issues <- list()
  
  #initialize startAt parameter for pagination
  startAt <- 0
  
  
  repeat {
  # Prepare query parameters including jql query, list of fields and maxresults to return
  query_params <- list(jql = jql_query, fields = paste(fields, collapse = ","), maxResults = maxResults, startAt = startAt)
  
  # Make the API call using httr::GET to the constructed URL using the query parameters above
  response <- httr::GET(url, query = query_params)
  
  # Check for HTTP errors and if there is an error, stops the call
  if (httr::http_error(response)) {
    stop("API request failed: ", httr::http_status(response)$message)
  }
  
  
  
  
  
  # Parse the response - extracts as text - converts JSON to R object and extracts "issues"
  # This line of code is taking an HTTP response, extracting its content as text, parsing that text as JSON, converting it to an R object without simplifying it into vectors, and then accessing the issues part of the resulting structure
  
 # issues <- jsonlite::fromJSON(httr::content(response, "text", encoding = "UTF-8"), simplifyVector = FALSE)$issues
  
  
  #downloads raw data
  #issues <- httr::content(response, "text", encoding = "UTF-8")
  
  
  
  # Parse the response and extract "issues"
    fetched_issues <- jsonlite::fromJSON(httr::content(response, "text", encoding = "UTF-8"), simplifyVector = FALSE)$issues
    
    # Append fetched issues to all_issues list
    all_issues <- c(all_issues, fetched_issues)
    
    # Verbose output for fetched issues
    if (verbose) {
      message("Fetched ", length(fetched_issues), " issues starting from ", startAt)
    }
    
    # Break the loop if the number of fetched issues is less than maxResults, indicating the last page
    if (length(fetched_issues) < maxResults) {
      break
    }
    
    # Increment startAt for the next page
    startAt <- startAt + maxResults
  } #end repeat loop
  
  
    # Save the issues to the specified path
  jsonlite::write_json(issues, save_path_issue_tracker_issues)
  
  # Verbose output
  if (verbose) {
    message("Fetched and saved ", length(issues), " issues to '", save_path_issue_tracker_issues, "'.")
  }
  
  # Returns nothing
  return(invisible(NULL)) # Return invisibly since the primary output is the saved file
}

```

# Define the variables required for the function call. This chunk also specifies the fields to be downloaded

```{r eval=FALSE}
# Define the parameters
# issue_tracker_domain <- conf[["issue_tracker"]][["jira"]][["domain"]]
jql_query <- paste0("project='",issue_tracker_project_key,"'")
fields <- c("summary", 
                           "description",
                           "creator",
                           "assignee",
                           "reporter",
                           "issuetype",
                           "status",
                           "resolution",
                           "components",
                           "created",
                           "updated",
                           "resolutiondate")
# save_path_issue_tracker_issues <- conf[["issue_tracker"]][["jira"]][["issues"]]
# save_path_issue_tracker_issue_comments <- conf[["issue_tracker"]][["jira"]][["issue_comments"]]
maxResults <- 100  # Optional: Specify the maximum number of results to fetch
verbose <- TRUE    # Optional: Print operation messages


```


# Call the function fetch_and_save_jira_issues (defined on line 55)
```{r eval=FALSE}
# Call the function
fetch_and_save_jira_issues(issue_tracker_domain,
                           username, 
                           your_api_token, 
                           jql_query, 
                           fields, 
                           save_path_issue_tracker_issues, 
                           maxResults, 
                           verbose)

```















The json will be downloaded on the path specified in the project configuration file, which by default is `kaiaulu/kaiaulu/rawdata/issue_tracker`. We can then use Kaiaulu's function to parse the data into a tabular format. Since our request did not include the  `comment` field, only the issues table will be available. A few rows of the json issues is shown next:

```{r}
require(kaiaulu)
jira_issues_list <- parse_jira(save_path_issue_tracker_issues)
jira_issues <- jira_issues_list[["issues"]]
jira_comments <- jira_issues_list[["comments"]]
kable(jira_issues[7:8])
```

# Download Issue with Comments

In the same manner as before, we can perform the same function call, but including the field `comment`. This will result in the same table being generated but with the additional comment information per issue (if an issue has more than one comment, the issue id is repeated for each different comment). The comment is shown on the column `comment_comments_id`. 

The data of this table can be used to calculate `social smell metrics`, as it represents a form of developer communication. A notebook discussing how to use JIRA data as communication network and/or combining to mailing list data will be made available in the future. 

```{r eval = FALSE}
json_issue_comments <- get_jira_issues(jql_query = paste0("project='",issue_tracker_project_key,"'"),
                fields = c("summary",
                           "description",
                           "creator",
                           "assignee",
                           "reporter",
                           "issuetype",
                           "status",
                           "resolution",
                           "components",
                           "created",
                           "updated",
                           "resolutiondate",
                           "comment"),
                verbose=TRUE,
                as.data.frame = FALSE)
jsonlite::write_json(json_issue_comments,save_path_issue_tracker_issue_comments)
```

Since this time around we requested the issue data and comments, when using the `parse_jira` function, both the issues and comments table will be available from the parser. Since the issue table was already displayed, the following show a few rows of the issue comments table:

```{r}
jira_issue_comments <- parse_jira(save_path_issue_tracker_issue_comments)
jira_issues <- jira_issue_comments[["issues"]]
jira_comments <- jira_issue_comments[["comments"]]

kable(jira_comments[55:56])
```


